{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify Spacy Lemmas\n",
    "\n",
    "  * Spacy's lemmas are stored in a binary file as part of the model since version 2.2\n",
    "  * \n",
    "  \n",
    "  \n",
    "conda install spacy-lookups-data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the location of the lemma file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:35:31.748957Z",
     "start_time": "2020-02-16T11:35:31.743000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma file: C:\\Users\\Jens\\Anaconda3\\lib\\site-packages\\spacy_lookups_data\\data\\de_lemma_lookup.json\n"
     ]
    }
   ],
   "source": [
    "import spacy_lookups_data\n",
    "\n",
    "fname = spacy_lookups_data.de['lemma_lookup']\n",
    "print(f\"Lemma file: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:22:31.742299Z",
     "start_time": "2020-02-16T11:22:31.734341Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy_lookups_data\n",
    "\n",
    "spacy_lookups_data.de['lemma_lookup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:23:36.128448Z",
     "start_time": "2020-02-16T11:23:36.089478Z"
    }
   },
   "outputs": [],
   "source": [
    "?nlp.vocab.lookups.remove_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:28:39.629942Z",
     "start_time": "2020-02-16T11:28:39.265943Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy_lookups_data\n",
    "\n",
    "fname = spacy_lookups_data.de['lemma_lookup']\n",
    "\n",
    "with open(fname, 'r') as file:\n",
    "    lemma_lookup = json.load(file)\n",
    "\n",
    "lemma_lookup['Sonne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:29:52.180835Z",
     "start_time": "2020-02-16T11:29:50.821836Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab.lookups.add_table('lemma_lookup', lemma_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:30:10.164990Z",
     "start_time": "2020-02-16T11:30:10.158999Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab.lookups.tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:33:23.318117Z",
     "start_time": "2020-02-16T11:33:23.295108Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma file: C:\\Users\\Jens\\Anaconda3\\lib\\site-packages\\spacy_lookups_data\\data\\de_lemma_lookup.json\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Jens\\\\Anaconda3\\\\lib\\\\site-packages\\\\spacy_lookups_data\\\\data\\\\de_lemma_lookup.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b8be959db1e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Lemma file: {fname}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mlemma_lookup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Jens\\\\Anaconda3\\\\lib\\\\site-packages\\\\spacy_lookups_data\\\\data\\\\de_lemma_lookup.json'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy_lookups_data\n",
    "import json\n",
    "\n",
    "fname = spacy_lookups_data.de['lemma_lookup']\n",
    "\n",
    "with open(fname, 'r') as file:\n",
    "    lemma_lookup = json.load(file)\n",
    "\n",
    "nlp = spacy.load('de')\n",
    "\n",
    "# must be executed before first call to nlp\n",
    "nlp.vocab.lookups.remove_table('lemma_lookup')\n",
    "nlp.vocab.lookups.add_table('lemma_lookup', lemma_lookup)\n",
    "\n",
    "texts = [\"Ich sonne mich in der Sonne.\", \n",
    "         \"Dieser GÃ¤rtner wohnt im Haus.\"]\n",
    "\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    print(\" \".join([t.lemma_ for t in doc]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:17:19.554160Z",
     "start_time": "2020-02-16T11:17:19.542760Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab.lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\Jens\\Anaconda3\\lib\\site-packages\\spacy_lookups_data\\data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nouns from Wiktionary\n",
    "\n",
    "https://github.com/gambolputty/german-nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:53.674772Z",
     "start_time": "2019-10-20T18:36:51.816276Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "\n",
    "# IPython (Jupyter) setting: \n",
    "# Print out every value instead of just \"last_expr\" (default)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:55.230494Z",
     "start_time": "2019-10-20T18:36:53.683755Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('nouns.csv', low_memory=False)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:55.246496Z",
     "start_time": "2019-10-20T18:36:55.235496Z"
    }
   },
   "outputs": [],
   "source": [
    "df['nominativ plural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:55.344499Z",
     "start_time": "2019-10-20T18:36:55.251496Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['lemma'] == 'Verkauf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:55.355499Z",
     "start_time": "2019-10-20T18:36:55.348498Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i, col in enumerate(df.columns):\n",
    "#    print(i, col)\n",
    "    \n",
    "cols = df.columns[16:]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:36:55.978029Z",
     "start_time": "2019-10-20T18:36:55.358498Z"
    }
   },
   "outputs": [],
   "source": [
    "df[cols] = df[cols].fillna('')\n",
    "df = df[df['pos'] == 'Substantiv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:37:42.066144Z",
     "start_time": "2019-10-20T18:36:55.978029Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "nouns = {}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    lemma = row['lemma']\n",
    "    \n",
    "    # skip non-nouns, tokens with specials and acronyms\n",
    "    if re.search(r'[,\\-\\s\\.0-9]', lemma)!=None or re.search(r'[A-Z]', lemma[1:])!=None:\n",
    "        continue\n",
    "        \n",
    "    nouns[lemma] = lemma\n",
    "\n",
    "    # add flex forms\n",
    "    for col in cols:\n",
    "        flex = row[col]\n",
    "\n",
    "        if flex != None and len(flex) > 1 and \\\n",
    "           re.search(r'[,\\-\\s\\.0-9]', flex)==None and re.search(r'[A-Z]', flex[1:])==None:\n",
    "            nouns[flex] = lemma\n",
    "            \n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:37:42.078126Z",
     "start_time": "2019-10-20T18:37:42.071120Z"
    }
   },
   "outputs": [],
   "source": [
    "nouns['Haus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:37:42.092117Z",
     "start_time": "2019-10-20T18:37:42.082120Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = orig_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:37:42.177117Z",
     "start_time": "2019-10-20T18:37:42.095123Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df.lemma == 'All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:37:42.194117Z",
     "start_time": "2019-10-20T18:37:42.179124Z"
    }
   },
   "outputs": [],
   "source": [
    "df.pos.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:34:18.116101Z",
     "start_time": "2019-10-19T09:34:18.112103Z"
    }
   },
   "source": [
    "# Correction of spaCy's German Lemmas v.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:05:37.490064Z",
     "start_time": "2020-02-16T11:05:37.416063Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab.lookups.get_table('lemma_lookup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[16219792130206718131]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:38:59.907030Z",
     "start_time": "2019-10-20T18:38:57.486271Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy.lang.de.lemmatizer import LOOKUP\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:44:18.587956Z",
     "start_time": "2019-10-20T18:44:17.848966Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = sys.stdout\n",
    "file = open(\"lemmatizer_de.py\", \"w\", encoding='utf-8')\n",
    "# file = open(\"lemmatizer_de_changes.py\", \"w\", encoding='utf-8')\n",
    "\n",
    "file.write(\"\"\"# coding: utf8\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "LOOKUP_DELTA = {\\n\"\"\")\n",
    "\n",
    "for word, lemma in LOOKUP.items():\n",
    "    try:\n",
    "        if word[0].isupper() and lemma.islower() and word.lower() not in LOOKUP and word in nouns:\n",
    "            new_lemma = nouns[word]\n",
    "            file.write(f'    \"{word}\": \"{new_lemma}\",\\n')\n",
    "            # file.write(f'    \"{word}\": \"{new_lemma}\", # previous \"{lemma}\"\\n')\n",
    "            # print(f'    \"{word}\": \"{new_lemma}\" # previous \"{lemma}\"')\n",
    "        else:\n",
    "            # pass\n",
    "            file.write(f'    \"{word}\": \"{lemma}\",\\n')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'    \"{word}\": \"{lemma}\"')\n",
    "        break\n",
    "            \n",
    "file.write(\"}\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:17:01.624739Z",
     "start_time": "2019-10-19T09:17:01.613763Z"
    }
   },
   "outputs": [],
   "source": [
    "word = \"Banden\"\n",
    "word[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:22:13.101266Z",
     "start_time": "2019-10-19T09:22:13.094239Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Banden\"[:-1] in LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:21:48.353093Z",
     "start_time": "2019-10-19T09:21:48.347092Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Bande\" in LOOKUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:39:02.151608Z",
     "start_time": "2019-10-20T18:39:01.781390Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T10:37:28.776233Z",
     "start_time": "2019-10-19T10:37:28.752234Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_nlp(doc, include_punct=False):\n",
    "    \"\"\"Print tokens with attributes for spaCy doc.\"\"\"\n",
    "    rows = []\n",
    "    for token in doc:\n",
    "        if not token.is_punct or include_punct:\n",
    "            row = (token.text, token.lemma_, \n",
    "                   token.pos_, token.tag_, token.dep_,\n",
    "                   token.is_punct, token.is_alpha, token.is_stop,\n",
    "                   token.ent_type_, token.ent_iob_)\n",
    "            rows.append(row)\n",
    "\n",
    "    # generate HTML formatted table for display in Jupyter\n",
    "    headers = ['text', 'lemma_', 'pos_', 'tag_', 'dep_', \n",
    "               'is_punct', 'is_alpha', 'is_stop', 'ent_type', 'ent_iob'] \n",
    "    display(HTML(tabulate(rows, headers=headers, tablefmt='html')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T11:19:38.648478Z",
     "start_time": "2019-10-19T11:19:38.641414Z"
    }
   },
   "outputs": [],
   "source": [
    "from lemmatizer_de import LOOKUP as my_LOOKUP\n",
    "\n",
    "nlp.vocab.morphology.lemmatizer.lookup_table = my_LOOKUP\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:39:22.293823Z",
     "start_time": "2019-10-20T18:39:22.277842Z"
    }
   },
   "outputs": [],
   "source": [
    "LOOKUP['Baum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:39:02.151608Z",
     "start_time": "2019-10-20T18:39:01.781390Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('de')\n",
    "#nlp = spacy.load('de')\n",
    "\n",
    "def print_nlp(doc):\n",
    "    print(\" \".join([f\"{t}/{t.lemma_}/{t.pos_}\" for t in doc if not t.is_punct]))\n",
    "\n",
    "texts = \"\"\"Dieser GÃ¤rtner wohnt im Haus.\n",
    "\"\"\"\n",
    "\n",
    "for text in texts.split(\"\\n\"):\n",
    "    doc = nlp(text)\n",
    "    print_nlp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T11:31:47.743018Z",
     "start_time": "2019-10-19T11:31:47.560916Z"
    }
   },
   "source": [
    "# SpaCy 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-16T11:02:08.271703Z",
     "start_time": "2020-02-16T11:02:08.264733Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, r'/home/albrecht/spacy/spaCy')\n",
    "sys.path.insert(0, r'/home/albrecht/spacy/spacy-lookups-data')\n",
    "\n",
    "for p in sys.path:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:39:02.151608Z",
     "start_time": "2019-10-20T18:39:01.781390Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('de')\n",
    "#nlp = spacy.load('de')\n",
    "\n",
    "def print_nlp(doc):\n",
    "    print(\" \".join([f\"{t}/{t.lemma_}/{t.pos_}\" for t in doc if not t.is_punct]))\n",
    "\n",
    "texts = \"\"\"Dieser GÃ¤rtner wohnt im Haus.\n",
    "\"\"\"\n",
    "\n",
    "for text in texts.split(\"\\n\"):\n",
    "    doc = nlp(text)\n",
    "    print_nlp(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"/home/albrecht/spacy/spacy-lookups-data/spacy_lookups_data/data/\"\n",
    "with open(path+\"de_lemma_lookup.json\", \"r\") as file:\n",
    "    LOOKUP = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOOKUP['Haus']\n",
    "LOOKUP['GÃ¤rtner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-20T18:44:18.587956Z",
     "start_time": "2019-10-20T18:44:17.848966Z"
    }
   },
   "outputs": [],
   "source": [
    "file = sys.stdout\n",
    "# file = open(\"lemmatizer_de.py\", \"w\", encoding='utf-8')\n",
    "# file = open(\"lemmatizer_de_changes.py\", \"w\", encoding='utf-8')\n",
    "\n",
    "new_lookup = {}\n",
    "\n",
    "for word, lemma in LOOKUP.items():\n",
    "    try:\n",
    "        if word[0].isupper() and lemma.islower() and word.lower() not in LOOKUP and word in nouns:\n",
    "            new_lemma = nouns[word]\n",
    "            new_lookup[word] = new_lemma\n",
    "            # file.write(f'    \"{word}\": \"{new_lemma}\",\\n')\n",
    "            # file.write(f'    \"{word}\": \"{new_lemma}\", # previous \"{lemma}\"\\n')\n",
    "            print(f'    \"{word}\": \"{new_lemma}\" # previous \"{lemma}\"')\n",
    "        else:\n",
    "            # pass\n",
    "            new_lookup[word] = LOOKUP[word]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'    \"{word}\": \"{lemma}\"')\n",
    "        break\n",
    "        \n",
    "new_lookup['Aber'] = 'aber'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:17:01.624739Z",
     "start_time": "2019-10-19T09:17:01.613763Z"
    }
   },
   "outputs": [],
   "source": [
    "new_lookup['Haus']\n",
    "new_lookup['GÃ¤rtner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_lookup)\n",
    "len(LOOKUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "path = \"/home/albrecht/spacy/spacy-lookups-data/spacy_lookups_data/data/\"\n",
    "with open(path+\"de_lemma_lookup.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(json.dumps(new_lookup, indent=4, ensure_ascii=False)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lookup['AbbrÃ¶ckelnden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, word in enumerate(new_lookup.keys()):\n",
    "    print(i, word)\n",
    "    if i > 200:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:22:13.101266Z",
     "start_time": "2019-10-19T09:22:13.094239Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Banden\"[:-1] in LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T09:21:48.353093Z",
     "start_time": "2019-10-19T09:21:48.347092Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Bande\" in LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T09:57:39.642637Z",
     "start_time": "2019-10-22T09:57:39.183347Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-22T09:57:00.517877Z",
     "start_time": "2019-10-22T09:57:00.503879Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.vocab.lookups.get_table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
